{"./":{"url":"./","title":"一、Introduction","keywords":"","body":"Introduction 记录组会内容 记录每天的学习进展 "},"chapter2/2月6日.html":{"url":"chapter2/2月6日.html","title":"2月6日组会","keywords":"","body":"2月6日组会 一、已经完成的工作 虚拟机中的代码整理与上传； 实现了分布式机器学习主从架构； 手动停止gitbook狗头转动 gitbook内容复制 二、下周的工作 【1】PyTorch支持哪些机器学习的模型（线性回归、逻辑回归、决策树、SVM、k-means、神经网络、高级神经网络-如：图神经网络等）？ 【2】如果PyTorch不支持决策树/SVM/k-means等，能否找到其他支持分布式机器学习的包（可能sklearn），这个包同时支持分布式的决策树/SVM/k-means？ "},"chapter2/2月12日.html":{"url":"chapter2/2月12日.html","title":"2月12日","keywords":"","body":"2月12日 1. 学习内容 在GitHub上找到一个Pytorch、Scikit-learn实现多种分类方法，包括逻辑回归（Logistic Regression）、多层感知机（MLP）、支持向量机（SVM）、K近邻（KNN）、CNN、RNN，极简代码适合新手小白入门，附英文实验报告（ACM模板）的仓库 2. 问题 [ ] 这些分类方法能否并行化？并行化的原理？PyTorch能否替代实现？ [x] FATE上是否有、决策树、SVM、k-means案例？ 没有 纵向: LogisticRegression(benchmark_quality/hetero_lr) LinearRegression(benchmark_quality/hetero_linear_regression) SecureBoost(benchmark_quality/hetero_sbt) FastSecureBoost(benchmark_quality/hetero_fast_sbt), NN(benchmark_quality/hetero_nn) 横向: LogisticRegression(benchmark_quality/homo_lr) SecureBoost(benchmark_quality/homo_sbt) NN(benchmark_quality/homo_nn [x] PyTorch相关的书上是否有案例？？ 没有 PyTorch是深度学习网络，支持线性回归，逻辑回归、卷积神经网络，循环神经网络，生成对抗网络 SVM需要自己改写 [x] PyTorch分布式都支持哪些网络呢？ CNN、RNN、LSTM1 [x] sklearn如何分布式呢？ sklearn 是 python 中一个非常著名的机器学习库，但是一般都是在单机上使用而不支持分布式计算，因此往往跟大规模的机器学习扯不上关系。这里通过 sklearn 进行的大规模机器学习指的也不是分布式机器学习，而是指当数据量比内存要大时怎么通过 sklearn 进行机器学习，更准确来说是 out-of-core learning， 这里涉及到的一个核心思想是将数据转化为流式输入，然后通过 SGD 更新模型的参数 2 Scikit-learn使用joblib库在其估计器中支持并行计算。有关控制并行计算的开关，请参阅joblib文档。 sk-dist是一个用于机器学习的Python模块，构建于scikit-learn之上，并在Apache 2.0软件许可下发布。sk-dist模块可以被认为是“分布式scikit-learn”，因为它的核心功能是将scikit-learn内置的joblib并行化的meta-estimator训练扩展到spark。 3. KNN可以实现并行化 3.1 KNN算法原理 1. 欧式距离： 欧氏距离定义： 欧氏距离（ Euclidean distance）是一个通常采用的距离定义，它是在m维空间中两个点之间的真实距离。 在二维和三维空间中的欧式距离的就是两点之间的距离，二维的公式是： 三维的公式是： 推广到n维空间，欧式距离的公式是： n维欧氏空间是一个点集，它的每个点可以表示为(x(1), x(2), …, x(n))，其中x(i)(i=1,2…n)是实数称为x的第i个坐标，两个点x和y之间的距离d(x, y)定义为上面的公式。 2. KNN算法的基本思想即传统KNN算法的的性能瓶颈 KNN算法是一种很简单的分类算法，不需要构建模型，直接通过训练数据对测试数据进行分类，首先要定义一种度量样本之间距离的方法，对于鸢尾花数据集我所选用的是欧氏距离，只需要计算测试数据到所有训练数据的欧式距离，然后升序排列，取前N个数据的标签通过投票的方式来决定测试数据的样本，哪个类票数多就分为哪个类。 传统KNN算法在分析大数据的时候，当训练数据或者测试数据很大的时候，由于单机内存有限和单机计算资源有限，导致传统KNN算法失效，所以我们需要对其进行并行化实现。 3. 并行化KNN MapReduce的核心思想是分而治之，KNN之所以能够实现并行化是因为每个训练样本不受其他训练样本影响。因为训练数据量大所以将训练数据分布式存储读入map，因为测试数据量小所以将测试数据量作为全局文件读入，在map中每输入一个训练样本就计算它和所有测试数据的距离并传到reduce，然后reduce将同一个测试数据的距离合并然后排序计数得到标签，再输出。 3.2 MapReduce原理 MapReduce是一种分布式数据处理技术，用于在大规模数据集上进行大量数据处理。它是一个高效的，简单易用的分布式系统，用于把大量的数据分成若干个小份，然后分布到多个节点上处理，最后再把所有的结果组合在一起。 MapReduce工作流程如下： Map阶段：该阶段对每一份数据执行一个映射函数，将数据映射成（键，值）对的形式，即（Key, Value）。 Shuffle阶段：该阶段把所有的（键，值）对根据键进行分组，每个组都被分配到一个Reduce节点上。 Reduce阶段：该阶段对每个分组执行一个归纳函数，把所有值合并成一个输出。 MapReduce把数据处理任务分解成许多独立的任务，每个任务都是一个可以独立执行的任务。因此，MapReduce的效率很高，同时，由于任务的分解和分布，MapReduce也很容易扩展。 [!NOTE|style:flat] KNN使用sklearn实现的，能否和PyTorch分布式包结合使用？ 4. 数据并行计算的机器学习算法（ChatGPT） 以下是一些可以进行数据并行计算的机器学习算法： 分布式随机森林（Distributed Random Forest）：该算法将数据分为多个部分并在分布式环境中并行计算，以加快模型训练速度。 大规模支持向量机（Massive Scale Support Vector Machine）：该算法利用并行计算加速模型训练过程。 分布式神经网络（Distributed Neural Network）：该算法通过分布式环境计算不同的神经元，以加快模型训练速度。 分布式梯度下降（Distributed Gradient Descent）：该算法将数据分布在多个节点，通过并行计算减少训练时间。 这些算法可以使用工具如Hadoop、Spark等进行实现，以加快模型训练速度和提高计算效率 5. 分布式图神经网络（支持PyTorch） 总结 PyTorch分布式不支持决策树、KNN、SVM的训练， 这些机器学习算法可能需要sklearn和spark sk-dist可以应用哪些分布式场景中？ 数据并行的机器学习算法使用什么实现的，查一查名字 高级的网络需要进一步的查资料 链接 1. 舒娜,刘波,林伟伟,李鹏飞.分布式机器学习平台与算法综述[J].计算机科学,2019,46(03):9-18. ↩ 2. https://wulc.me/2017/08/08/%E9%80%9A%E8%BF%87%20sklearn%20%E8%BF%9B%E8%A1%8C%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ ↩ "},"chapter2/2月13日.html":{"url":"chapter2/2月13日.html","title":"2月13日","keywords":"","body":"2月13日 1. 上次的问题 [x] sk-dist可以应用哪些分布式场景中？ [ ] 数据并行的机器学习算法使用什么实现的，查一查名字 [ ] 高级的网络需要进一步的查资料 1.1 sk-dist应用场景 可以应用于决策树随机森林 2. kmeans分布式实现 knn属于监督学习,类别是已知的,通过对已知分类的数据进行训练和学习,找到这些不同类的特征,再对未分类的数据进行分类。kmeans属于非监督学习,事先不知道数据会分为几类,通过聚类分析将数据聚合成几个群体。 kmeans算法很简单 随机选择k个样本点作为初始中心点。 计算样本到所有k个中心点的距离，距离最近的标记成对应的类别。 计算新的中心点，返回步骤二，直到所有样本点标记不再变化。 3. PyTorch实现决策树和决策树 4. 什么是机器学习流水线 模型训练只是机器学习整个过程中很小的一部分。 数据科学家们在整个机器学习的过程中要花费大量的时间在数据清洗，转换和准备数据集。 上面讲的整个过程称为机器学习流水线。 流水新中的每一步产生的输出为下一步提供输入。 其中的每一步可以帮助我们获得更好的结果和更清晰的数据。 机器学习系统与实现 在分布式方面写的很详细 分布式机器学习框架综述 介绍了深度学习分布式框架和传统的机器学习分布式框架 需要查一下提到的相关框架 1. 基于Spark自动扩展scikit-learn(spark-sklearn) Scikit-learn是传统机器学习算法中常用的框架,但是,Scikit-learn的优势通常在于单个节点上的计算领域。对于某些常见方案，例如参数调整，可以并行运行大量小任务。这些场景对应Spark简直完美,因此将Spark和Scikit-learn结合,使用Spark集群对训练任务进行分工和调度将会加快训练过程. 由Databricks开源的spark-sklearn框架,它结合了Spark和scikit-learn的优势,无需更改用户代码就可实现分布式训练。它重新实现了scikit-learn的某些组件,用户将看到与scikit-learn的交叉验证工具完全兼容的基于Spark的交叉验证器类。通过交换单个类导入，用户可以为他们现有的scikit-learn工作流分配交叉验证 2. Sparkit-learn Sparkit-learn aims to provide scikit-learn functionality and API on PySpark. The main goal of the library is to create an API that stays close to sklearn's. 3. LightGBM Distributed Learning Guide 4. PMLS 支持逻辑回归、K-Means、随机森林、SVM、多分类逻辑回归、深度神经网络 分布式机器学习平台基本设计方法 我们将这些分布式机器学习平台归类为了三大基本设计方法： 基本数据流(basic dataflow) 参数服务器模型(parameter-server model) 先进数据流(advanced dataflow) 我们对这三种方法进行了简要介绍并举例进行了说明，其中基本数据流方法使用了 Apache Spark、参数服务器模型使用了 PMLS(Petuum)、先进数据流模型使用了 TensorFlow 和 MXNet。我们提供了几个比较性能的评估结果。 总结 PyTorch 实现传统的机器学习困难 需要搞清楚需要那种通信拓扑结构 分布式机器学习系统基础需要看一看 "},"chapter2/2月14日组会.html":{"url":"chapter2/2月14日组会.html","title":"2月14日组会","keywords":"","body":"2月14日组会 问题： PMLS的搭建，原理流程和聚类/分类如何进行分布式学习？ 分布式机器学习通信原理 解决方式 创建一台新的虚拟机 安装spark 安装Hadoop 安装HDFS 安装PMLS，尝试分布式 尝试其他分布式平台 不同平台分布式通信原理，看书以及之前网上书的教程 "},"chapter2/2月14日.html":{"url":"chapter2/2月14日.html","title":"2月14日","keywords":"","body":"2月14日 1. 今日任务 创建一台新的虚拟机 安装常用软件，打包备份 安装spark 安装Hadoop 安装HDFS 安装PMLS，尝试分布式 "},"chapter2/2月17日.html":{"url":"chapter2/2月17日.html","title":"2月17日","keywords":"","body":"2月17日 百度网盘有相关大数据学习资料，包含机器学习部分 Ubuntu20.04版本装不了PMLS的相关依赖，PMLS文档支持的是Ubuntu14.4 spark单机版本地安装在Ubuntu20.04虚拟机下，使用jupyter notebook时存在报错，可能是更改了系统变量的原因 spark anaconda版本安装在spark虚拟机下，可以使用spark进行机器学习 问题 spark的集群部署 How to Run Spark With Docker gitbook的脚本推送存在问题 尝试在更低版的Ubuntu系统下安装PMLS "},"chapter2/2月21日组会.html":{"url":"chapter2/2月21日组会.html","title":"2月21日组会","keywords":"","body":"2月21日组会 问题： Spark的内存加速 怎样将机器模型转化为DAG的？ Master怎样分配资源给worker节点？ 查阅隐私保护方法能否用到DAG中？ "},"chapter2/2月28日组会.html":{"url":"chapter2/2月28日组会.html","title":"2月28日组会","keywords":"","body":"2月28日组会 问题： RDD的数据是如何被分配的？ RDD的基础操作有哪些？ RDD/DAG安全性能的文献？ Spark是否有隐私保护的需求？ "},"chapter3/3月3日.html":{"url":"chapter3/3月3日.html","title":"3月3日","keywords":"","body":"3月3日 问题： pysyft 0.2.4能否使用websockets调用差分隐私算法？ pysyft 0.2.4smpc能有在实现？ smpc能否应用到分布式部署？ Flower实现差分隐私？ 解决: 问题1： 1.1 websockets-example-MNIST-parallel 对于websockets-example-MNIST-parallel不能实现差分隐私，在模型参数的方法里就已经规定好optimizer的接收的是个string字符串 1.2 websockets-example-MNIST-parallel websockets-example-MNIST同样不支持差分隐私操作，因为optimizer访问到的权重和偏执是指针，没有办法裁剪。 问题2： 2.1 "},"other/win10远程桌面连接Ubuntu20.4.html":{"url":"other/win10远程桌面连接Ubuntu20.4.html","title":"win10远程桌面连接Ubuntu20.4","keywords":"","body":"win10远程桌面连接Ubuntu20.4 一、内网穿透 1. 使用ZeroTier创建网络 2. 设备安装ZeroTier客户端，加入网络 2.1 linux设备安装 1、在线安装zerotier curl -s https://install.zerotier.com/ | sudo bash 2、添加开机自启 $ sudo systemctl enable zerotier-one.service 3、启动zerotier-one.service $ sudo systemctl start zerotier-one.service 4、加入网络 $ sudo zerotier-cli join 网络识别码 2.2 Windows设备安装（略） 2.3 在ZeroTier上同意设备加入网络 二、Ubuntu安装xrdp 1、安装 xrdp sudo apt-get install xrdp 2、开启rdp服务 systemctl start xrdp 3、使 rdp 开机自启 systemctl enable xrdp 遇到问题，连接黑屏 修改配置： sudo vi /etc/xrdp/startwm.sh 添加以下两句 unset DBUS_SESSION_BUS_ADDRESS unset XDG_RUNTIME_DIR 在此处上面添加 if test -r /etc/profile; then . /etc/profile fi 重启 xrdp 服务： sudo systemctl restart xrdp 三、Windows开启远程桌面 3.1 输入ZeroTier提供的IP地址 3.2 连接成功 四、使用Ubuntu原生主题 如果不做任何配置，启动之后的桌面是非常别扭的，因为是Gnome的原始桌面，没有左侧的任务栏，窗口也没有最小化按钮，等等一些列问题。解决方案也很简单： 1. 添加配置文件 vim ~/.xsessionrc 添加： export GNOME_SHELL_SESSION_MODE=ubuntu export XDG_CURRENT_DESKTOP=ubuntu:GNOME export XDG_CONFIG_DIRS=/etc/xdg/xdg-ubuntu:/etc/xdg 2. 重启xrdp服务 sudo systemctl restart xrdp.service 此时再连接，你将得到与原生桌面完全一样的效果！ 参考链接 linux 安装配置zerotier win10远程桌面连接ubuntu20(RDP) Windows远程桌面连接Ubuntu图文教程 完美方案——解决XRDP连接黑屏，以及桌面优化！ "},"other/pip修改镜像源.html":{"url":"other/pip修改镜像源.html","title":"pip修改镜像源","keywords":"","body":"pip修改镜像源 一、国内常用镜像源汇总 1 清华镜像 https://pypi.tuna.tsinghua.edu.cn/simple 2 中科大镜像 https://pypi.mirrors.ustc.edu.cn/simple 3 豆瓣镜像 http://pypi.douban.com/simple/ 3 阿里镜像 https://mirrors.aliyun.com/pypi/simple/ 4 华中科大镜像 http://pypi.hustunique.com/ 5 山东理工大学镜像 http://pypi.hustunique.com/ 6 搜狐镜像 http://mirrors.sohu.com/Python/ 7 百度镜像 https://mirror.baidu.com/pypi/simple 二、手动切换镜像源 #全局设置镜像源地址 pip config set global.index-url https://pypi.mirrors.ustc.edu.cn/simple 三、查看更改后的镜像源 pip config list "},"other/git分支+Pycharm.html":{"url":"other/git分支+Pycharm.html","title":"git分支+Pycharm","keywords":"","body":"git分支+Pycharm 一、什么是git分支？ 二、新建分支 1. 远程创建分支 2. 本地刷新 2.1 点击刷新 2.2 或者更新项目 2.3 查看 3. 本地新建分支 点击master，选择新建分支 三、修改代码 3.1 commit 3.2 push远程分支 可以观察到master分支没有改变 Dev分支有改变 四、切换分支 在右下角点击切换分支，选择checkout 五、合并分支 "}}